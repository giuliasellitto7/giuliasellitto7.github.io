@article{ferrara2023fairness,
	title = {Fairness-aware machine learning engineering: how far are we?},
	volume = {29},
	issn = {1573-7616},
	url = {https://doi.org/10.1007/s10664-023-10402-y},
	doi = {10.1007/s10664-023-10402-y},
	abstract = {Machine learning is part of the daily life of people and companies worldwide. Unfortunately, bias in machine learning algorithms risks unfairly influencing the decision-making process and reiterating possible discrimination. While the interest of the software engineering community in software fairness is rapidly increasing, there is still a lack of understanding of various aspects connected to fair machine learning engineering, i.e., the software engineering process involved in developing fairness-critical machine learning systems. Questions connected to the practitionersâ€™ awareness and maturity about fairness, the skills required to deal with the matter, and the best development phase(s) where fairness should be faced more are just some examples of the knowledge gaps currently open. In this paper, we provide insights into how fairness is perceived and managed in practice, to shed light on the instruments and approaches that practitioners might employ to properly handle fairness. We conducted a survey with 117 professionals who shared their knowledge and experience highlighting the relevance of fairness in practice, and the skills and tools required to handle it. The key results of our study show that fairness is still considered a second-class quality aspect in the development of artificial intelligence systems. The building of specific methods and development environments, other than automated validation tools, might help developers to treat fairness throughout the software lifecycle and revert this trend.},
	number = {1},
	journal = {Empirical Software Engineering},
	author = {Ferrara, Carmine and Sellitto, Giulia and Ferrucci, Filomena and Palomba, Fabio and De Lucia, Andrea},
	month = nov,
	year = {2023},
	pages = {9},
}
